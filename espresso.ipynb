{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "import shlex\n",
    "import logging\n",
    "import shutil\n",
    "import re\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "log = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "WORK_DIR = 'work'\n",
    "HELPDOC_FILES = ['dev-tools/helpdoc', 'dev-tools/helpdoc.d', 'dev-tools/helpdoc.schema', 'dev-tools/input_xx.xsl', 'GUI/Guib/lib']\n",
    "DEFS_TO_PARSE = ['PW/Doc/INPUT_PW.def', 'PP/Doc/INPUT_PROJWFC.def']\n",
    "VERSION = ['6.3', '6.8', '7.0', '7.2']\n",
    "DATABSE_DIR = 'database/espresso'\n",
    "gen_docs = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_command(command):\n",
    "    log.debug(f\"Command: {command}\")\n",
    "    command = shlex.split(command)\n",
    "    result = subprocess.run(command, capture_output=True, check=True)\n",
    "    if result.stdout:\n",
    "        log.debug(f\"Command stdout: {result.stdout.decode('utf-8')}\")\n",
    "    if result.stderr:\n",
    "        log.debug(f\"Command stderr: {result.stderr.decode('utf-8')}\")\n",
    "    return result\n",
    "\n",
    "def generate_help_files(WORK_DIR, HELPDOC_FILES, DEFS_TO_PARSE, VERSION, DATABSE_DIR):\n",
    "    # Create work directory and go there\n",
    "    root = os.getcwd()\n",
    "    work_dir = os.path.join(root, WORK_DIR)\n",
    "    # TODO: this is temporary\n",
    "    if os.path.exists(work_dir):\n",
    "        shutil.rmtree(work_dir)\n",
    "    if not os.path.exists(work_dir):\n",
    "        os.makedirs(work_dir)\n",
    "    os.chdir(work_dir)\n",
    "\n",
    "    # Commands to set up minimal helpdoc environment\n",
    "    qe_dir = os.path.join(work_dir, 'q-e')\n",
    "    cmd_clone = \"git clone --filter=blob:none --sparse https://gitlab.com/QEF/q-e.git\"\n",
    "    run_command(cmd_clone)\n",
    "    os.chdir(qe_dir)\n",
    "    cmd_fetch_tags = \"git fetch --all --tags\"\n",
    "    run_command(cmd_fetch_tags)\n",
    "\n",
    "    cmd_checkout_files = [\"git sparse-checkout add\"]\n",
    "    cmd_checkout_files = \" \".join(cmd_checkout_files + HELPDOC_FILES + DEFS_TO_PARSE)\n",
    "    run_command(cmd_checkout_files)\n",
    "\n",
    "    # Commands for picking the right version\n",
    "    devtools_dir = os.path.join(qe_dir, 'dev-tools')\n",
    "    for v in VERSION:\n",
    "        tag = v\n",
    "        tag += \"MaX\" if v in (\"6.3\", \"6.5\") else \"\"\n",
    "        tag += \"MaX-Release\" if v == \"6.7\" else \"\"\n",
    "        cmd_checkout_tag = f\"git checkout tags/qe-{tag} -b qe-{tag}\"\n",
    "        run_command(cmd_checkout_tag)\n",
    "        database_dir = os.path.join(root, DATABSE_DIR, v)\n",
    "        if not os.path.exists(database_dir):\n",
    "            os.makedirs(database_dir)\n",
    "\n",
    "        files = [os.path.join(qe_dir, def_file) for def_file in DEFS_TO_PARSE]\n",
    "        for def_file in files:\n",
    "            dir = os.path.dirname(def_file)\n",
    "            cmd_link_xsl = f\"ln -sf {devtools_dir}/input_xx.xsl {dir}/input_xx.xsl\"\n",
    "            run_command(cmd_link_xsl)\n",
    "            cmd_helpdoc = f\"{devtools_dir}/helpdoc --version {v} {def_file}\"\n",
    "            run_command(cmd_helpdoc)\n",
    "\n",
    "            # Copy the generated files to the database directory using os module\n",
    "            xml_file = os.path.splitext(def_file)[0] + '.xml'\n",
    "            html_file = os.path.splitext(def_file)[0] + '.html'\n",
    "            # Explicit destination is needed to overwrite existing files\n",
    "            shutil.move(html_file, os.path.join(database_dir, os.path.basename(html_file)))\n",
    "            shutil.move(xml_file, os.path.join(database_dir, os.path.basename(xml_file)))\n",
    "\n",
    "    os.chdir(root)\n",
    "\n",
    "if gen_docs:\n",
    "    generate_help_files(WORK_DIR, HELPDOC_FILES, DEFS_TO_PARSE, VERSION, DATABSE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import xmltodict\n",
    "#import re\n",
    "#\n",
    "#def parse_vargroup(vargroup):\n",
    "#    vars = []\n",
    "#    info = vargroup['info']\n",
    "#    type = vargroup['@type']\n",
    "#    for v in vargroup['var']:\n",
    "#        name = v['@name']\n",
    "#        vars.append({\n",
    "#            '@name': name,\n",
    "#            '@type': type,\n",
    "#            'info': info,\n",
    "#        })\n",
    "#    return vars \n",
    "#\n",
    "#def find_all_vars(namelist):\n",
    "#    vars = []\n",
    "#    if 'var' in namelist.keys():\n",
    "#        vars.extend(namelist['var'])\n",
    "#    if 'multidimension' in namelist.keys():\n",
    "#        vars.extend(namelist['multidimension'])\n",
    "#    if 'dimension' in namelist.keys():\n",
    "#        vars.extend(namelist['dimension'])\n",
    "#    if 'vargroup' in namelist.keys():\n",
    "#        vargroups = namelist['vargroup']\n",
    "#        if isinstance(vargroups, dict):\n",
    "#            vargroups = [vargroups]\n",
    "#        for vg in vargroups:\n",
    "#            vars.extend(parse_vargroup(vg))\n",
    "#    if 'group' in namelist.keys():\n",
    "#        groups = namelist['group']\n",
    "#        if isinstance(groups, dict):\n",
    "#            groups = [groups]\n",
    "#        for g in groups:\n",
    "#            vars.extend(find_all_vars(g))\n",
    "#    return vars\n",
    "#\n",
    "#pattern = re.compile(r'<a href=\"(.*?)\">\\s*(.*?)\\s*</a>')\n",
    "#with open(os.path.join(DATABSE_DIR, '7.2', 'INPUT_PW.xml'), 'r') as f:\n",
    "#    xmltext = f.read()\n",
    "#    xmltext = xmltext.replace(\"<ref>\", \"\")\n",
    "#    xmltext = xmltext.replace(\"</ref>\", \"\")\n",
    "#    xmltext = pattern.sub(r'\\2 (\\1)', xmltext)\n",
    "#    doc = xmltodict.parse(xmltext)\n",
    "#\n",
    "#names = []\n",
    "#vars = []\n",
    "#for namelist in doc['input_description']['namelist']:\n",
    "#    names.append(namelist['@name'])\n",
    "#    vars.extend(find_all_vars(namelist))\n",
    "#\n",
    "#print(len(vars))\n",
    "\n",
    "#nls = doc['input_description']['namelist']\n",
    "#nls[1]['group'][0]\n",
    "#for nl in nls:\n",
    "#    if 'group' in nl.keys():\n",
    "#        print(f'Found group in {nl[\"@name\"]} with length {len(nl[\"group\"])}')\n",
    "#        if isinstance(nl['group'], dict):\n",
    "#            nl['group'] = [nl['group']]\n",
    "#        for g_i, g in enumerate(nl['group']):\n",
    "#            if 'vargroup' in g.keys():\n",
    "#                print(f'Found vargroup in {nl[\"@name\"]} group {g_i} with length {len(g[\"vargroup\"])}')\n",
    "#                if isinstance(g['vargroup'], dict):\n",
    "#                    g['vargroup'] = [g['vargroup']]\n",
    "#                for vg_i, vg in enumerate(g['vargroup']):\n",
    "#                    print(f'{nl[\"@name\"]} group {g_i} vargroup {vg_i} has length {len(vg[\"var\"])}')\n",
    "#        #if isinstance(nl['group'], dict):\n",
    "#        #    nl['group'] = [nl['group']]\n",
    "#        #for g in nl['group']:\n",
    "#        #    if 'vargroup' in g.keys():\n",
    "#        #        if isinstance(g['vargroup'], dict):\n",
    "#        #            g['vargroup'] = [g['vargroup']]\n",
    "#        #        for vg in g['vargroup']:\n",
    "#        #            print(vg)\n",
    "#        #print(nl['group'])\n",
    "#    if 'vargroup' in nl.keys():\n",
    "#        print(f'Found vargroup in {nl[\"@name\"]} with length {len(nl[\"vargroup\"])}')\n",
    "#        if isinstance(nl['vargroup'], dict):\n",
    "#            nl['vargroup'] = [nl['vargroup']]\n",
    "#        for vg_i, vg in enumerate(nl['vargroup']):\n",
    "#            print(f'{nl[\"@name\"]} vargroup {vg_i} has length {len(vg[\"var\"])}')\n",
    "#        #if isinstance(nl['vargroup'], dict):\n",
    "#        #    nl['vargroup'] = [nl['vargroup']]\n",
    "#        #for vg in nl['vargroup']:\n",
    "#        #    print(vg)\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "from io import StringIO\n",
    "\n",
    "def parse_vargroup(vg, parent):\n",
    "    vars = []\n",
    "    type = vg.attrib['type']\n",
    "    info = vg.find('info')\n",
    "    if info is not None:\n",
    "        info = info.text\n",
    "    \n",
    "    for v in vg.findall('var'):\n",
    "        v_dict = {\n",
    "            'name': v.attrib['name'],\n",
    "            'parent': parent,\n",
    "            'type': type,\n",
    "            'info': info,\n",
    "            'dimension': 1,\n",
    "            'default': ' ',\n",
    "            'options': {},\n",
    "        }\n",
    "        vars.append(v_dict)\n",
    "\n",
    "    return vars\n",
    "\n",
    "def parse_var(v, parent):\n",
    "    opts = v.find('options')\n",
    "\n",
    "    # Deal with Info\n",
    "    info = None\n",
    "    if opts is not None:\n",
    "        info = opts.find('info')\n",
    "    else:\n",
    "        info = v.find('info')\n",
    "    if info is not None:\n",
    "        info = info.text\n",
    "    else:\n",
    "        info = ''\n",
    "    \n",
    "    options = {}\n",
    "    if opts is not None:\n",
    "        for o in opts.findall('opt'):\n",
    "            options.update({o.attrib['val']: o.text})\n",
    "    \n",
    "    default = v.find('default')\n",
    "    if default is not None:\n",
    "        default = default.text\n",
    "    else:\n",
    "        default = ''\n",
    "\n",
    "    v_dict = {\n",
    "        'name': v.attrib['name'],\n",
    "        'parent': parent,\n",
    "        'type': v.attrib['type'],\n",
    "        'dimension': v.attrib.get('end', 1),\n",
    "        'info': info,\n",
    "        'default': default,\n",
    "        'options': options,\n",
    "    }\n",
    "\n",
    "    return v_dict\n",
    "\n",
    "def parse_group(g, parent):\n",
    "    vars = []\n",
    "    for e in g:\n",
    "        if e.tag in ('var', 'multidimension', 'dimension'):\n",
    "            vars.append(parse_var(e, parent))\n",
    "        elif e.tag == 'vargroup':\n",
    "            vars.extend(parse_vargroup(e, parent))\n",
    "        elif e.tag == 'group':\n",
    "            vars.extend(parse_group(e, parent)) \n",
    "    return vars\n",
    "\n",
    "type_map = {\n",
    "    \"character\": str,\n",
    "    \"real\": float,\n",
    "    \"integer\": int,\n",
    "    \"logical\": bool,\n",
    "}\n",
    "\n",
    "def tidy_dict(d):\n",
    "    tidy_d = {}\n",
    "    for k, v in d.items():\n",
    "        if isinstance(k, str):\n",
    "            k = tidy_str(k)\n",
    "        if v and isinstance(v, str):\n",
    "            v = tidy_str(v)\n",
    "        tidy_d[k] = v\n",
    "    return tidy_d\n",
    "\n",
    "def tidy_str(s):\n",
    "    s = s.replace('\\n', ' ').strip()\n",
    "    # If str is already a string, e.g., str = \"'hello'\", clean it up\n",
    "    if s and s[0] == \"'\" and s[-1] == \"'\":\n",
    "        s = s[1:-1]\n",
    "    return s\n",
    "\n",
    "def tidy_vars(vars):\n",
    "    clean_vars = []\n",
    "    for v in vars:\n",
    "        name = v[\"name\"]\n",
    "        parent = v[\"parent\"]\n",
    "        type = type_map[v[\"type\"].lower()]\n",
    "        dimension = v[\"dimension\"]\n",
    "        options = tidy_dict(v[\"options\"])\n",
    "        default = tidy_str(v[\"default\"])\n",
    "        info = tidy_str(v[\"info\"])\n",
    "\n",
    "        # Special cases\n",
    "        if name == 'A':\n",
    "            info = 'a in ANGSTROM'\n",
    "        elif name == 'B':\n",
    "            info = 'b in ANGSTROM'\n",
    "        elif name == 'C':\n",
    "            info = 'c in ANGSTROM'\n",
    "        elif name == 'cosAB':\n",
    "            info = 'cos angle between a and b (gamma)'\n",
    "        elif name == 'cosAB':\n",
    "            info = 'cos angle  between a and c (beta)'\n",
    "        elif name == 'cosBC':\n",
    "            info = 'cos angle between b and c (alpha)'\n",
    "        elif name == 'ibrav':\n",
    "            info = 'Bravais lattice choice'\n",
    "            options = {\n",
    "                0: \"Lattice in CELL_PARAMETERS\",\n",
    "                1: \"Cubic P (sc) lattice\",\n",
    "                2: \"Cubic F (fcc) lattice\",\n",
    "                3: \"Cubic I (bcc) lattice\",\n",
    "                -3: \"Cubic I (bcc) lattice\",\n",
    "                4: \"Hexagonal and Trigonal P lattice\",\n",
    "                5: \"Trigonal Rhombohedral lattice, 3-fold axis c\",\n",
    "                -5: \"Trigonal Rhombohedral lattice, 3-fold axis <111>\",\n",
    "                6: \"Tetragonal P (st) lattice\",\n",
    "                7: \"Tetragonal I (bct) lattice\",\n",
    "                8: \"Orthorhombic P lattice\",\n",
    "                9: \"Orthorhombic base-centered(bco) lattice\",\n",
    "                -9: \"Orthorhombic base-centered(bco) lattice\",\n",
    "                91: \"Orthorhombic one-face base-centered A-type lattice\",\n",
    "                10: \"Orthorhombic face-centered lattice\",\n",
    "                11: \"Orthorhombic body-centered lattice\",\n",
    "                12: \"Monoclinic P, unique axis c lattice\",\n",
    "                -12: \"Monoclinic P, unique axis b lattice\",\n",
    "                13: \"Monoclinic base-centered lattice\",\n",
    "                -13: \"Monoclinic base-centered lattice\",\n",
    "                14: \"Triclinic lattice\",\n",
    "            }\n",
    "        if type == bool and options == {}:\n",
    "            options = {\n",
    "                True: \"\",\n",
    "                False: \"\",\n",
    "            }\n",
    "        \n",
    "        clean_vars.append({\n",
    "            \"name\": name,\n",
    "            \"parent\": parent,\n",
    "            \"type\": type,\n",
    "            \"dimension\": dimension,\n",
    "            \"options\": options,\n",
    "            \"default\": default,\n",
    "            \"info\": info,\n",
    "        })\n",
    "    \n",
    "    return clean_vars\n",
    "\n",
    "def extract_vars(xml_filename):\n",
    "    pattern = re.compile(r'<a href=\"(.*?)\">\\s*(.*?)\\s*</a>')\n",
    "    with open(xml_filename, 'r') as f:\n",
    "        xmltext = f.read()\n",
    "        xmltext = xmltext.replace(\"<ref>\", \"\")\n",
    "        xmltext = xmltext.replace(\"</ref>\", \"\")\n",
    "        xmltext = xmltext.replace(\"<b>\", \"\")\n",
    "        xmltext = xmltext.replace(\"</b>\", \"\")\n",
    "        xmltext = pattern.sub(r'\\2 (\\1)', xmltext)\n",
    "        root = ET.parse(StringIO(xmltext)).getroot()\n",
    "\n",
    "    vars = []\n",
    "    #cards = []\n",
    "    for child in root:\n",
    "        if child.tag == 'namelist':\n",
    "            namelist_name = child.attrib['name']\n",
    "            for e in child:\n",
    "                if e.tag in ('var', 'multidimension', 'dimension'):\n",
    "                    vars.append(parse_var(e, namelist_name))\n",
    "                elif e.tag == 'vargroup':\n",
    "                    vars.extend(parse_vargroup(e, namelist_name))\n",
    "                elif e.tag == 'group':\n",
    "                    vars.extend(parse_group(e, namelist_name))\n",
    "        #elif child.tag == 'card':\n",
    "        #    cards.append(child)\n",
    "        \n",
    "    vars = tidy_vars(vars)\n",
    "\n",
    "    return vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_filename = os.path.join(DATABSE_DIR, '7.2', 'INPUT_PW.xml')\n",
    "vars = extract_vars(xml_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml.html import soupparser\n",
    "# Generates a map from name -> {idm, html}\n",
    "def gen_idm_map(soup):\n",
    "    idm_map = {}\n",
    "    # Find all links with href = \"#idm*\", their text is the name\n",
    "    links = soup.xpath('//a[starts-with(@href, \"#idm\")]')\n",
    "    for a in links:\n",
    "        name = a.text\n",
    "        if name.startswith('&'):\n",
    "            name = name[1:]\n",
    "        idm = a.attrib['href'][1:]\n",
    "        idm_map.update({name: {\"idm\": idm, \"html\": \"\"}})\n",
    "    # Find all th tags with text=name*, their grandparent is the table\n",
    "    for name, idm_dict in idm_map.items():\n",
    "        tags = soup.xpath(f'//th[starts-with(text(), \"{name}\")]')\n",
    "        for th in tags:\n",
    "            table = th.getparent().getparent()\n",
    "            idm_dict[\"html\"] = table\n",
    "\n",
    "    return idm_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5j/yxdm6w0d5nx3tvjnxt0y1qgr0000gq/T/ipykernel_14792/3643552602.py:23: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "  html = idm_map[name][\"html\"] if idm_map[name][\"html\"] else None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#def clean_html(html):\n",
    "#    cleaner = Cleaner(style=True, align=True, valign=True)\n",
    "#    if html is not None:\n",
    "#        for child in html.find_all(True):\n",
    "#            # Remove all attributes\n",
    "#            if 'style' in child.attrs:\n",
    "#                del child[attr]\n",
    "#    else:\n",
    "#        html = \"\"\n",
    "#    return html\n",
    "\n",
    "def add_html_info(vars, html_filename):\n",
    "    with open(html_filename, \"r\") as f:\n",
    "        #soup = BeautifulSoup(f, \"lxml\")\n",
    "        soup = soupparser.fromstring(f.read())\n",
    "\n",
    "    idm_map = gen_idm_map(soup)\n",
    "    link_base = \"file:///\" + os.path.join(os.getcwd(), html_filename) + \"#\"\n",
    "    for v in vars:\n",
    "        name = v[\"name\"]\n",
    "        if name in idm_map:\n",
    "            v[\"idm\"] = idm_map[name][\"idm\"]\n",
    "            html = idm_map[name][\"html\"] if idm_map[name][\"html\"] else None\n",
    "            #html = clean_html(html)\n",
    "            v[\"html\"] = html\n",
    "            v[\"link\"] = link_base + idm_map[name][\"idm\"]\n",
    "        else:\n",
    "            print(f\"WARNING: No HTML info for {name}\")\n",
    "    return vars\n",
    "\n",
    "\n",
    "html_filename = os.path.join(DATABSE_DIR, \"7.2\", \"INPUT_PW.html\")\n",
    "vars = add_html_info(vars, html_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the html of variable 20 to a file for testing\n",
    "with open(\"dirty.html\", 'w') as f:\n",
    "    f.write(vars[20]['html'].prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'HtmlElement' object has no attribute 'name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[209], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcopy\u001b[39;00m \u001b[39mimport\u001b[39;00m deepcopy\n\u001b[1;32m      3\u001b[0m html \u001b[39m=\u001b[39m deepcopy(\u001b[39mvars\u001b[39m[\u001b[39m20\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mhtml\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m----> 5\u001b[0m \u001b[39mif\u001b[39;00m html\u001b[39m.\u001b[39;49mname \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtable\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m      6\u001b[0m     html\u001b[39m.\u001b[39mclasses\u001b[39m.\u001b[39madd(\u001b[39m'\u001b[39m\u001b[39mtag-table\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      7\u001b[0m     to_delete \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mstyle\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39malign\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mvalign\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mwidth\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mcolspan\u001b[39m\u001b[39m'\u001b[39m]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'HtmlElement' object has no attribute 'name'"
     ]
    }
   ],
   "source": [
    "# Import deepcopy for me\n",
    "from copy import deepcopy\n",
    "html = deepcopy(vars[20]['html'])\n",
    "\n",
    "if html.name == 'table':\n",
    "    html.classes.add('tag-table')\n",
    "    to_delete = ['style', 'align', 'valign', 'width', 'colspan']\n",
    "    for attr in to_delete:\n",
    "        if attr in html.attrib:\n",
    "            del html.attrib[attr]\n",
    "    for child in html.find_all(True):\n",
    "        if child.name == 'th':\n",
    "            child.attrs['class'] = 'header-cell'\n",
    "        elif child.name == 'td':\n",
    "            if 'style' in child.attrs:\n",
    "                style = child['style']\n",
    "                if 'background-color' in style and 'text-align' in style:\n",
    "                    bgcol = style['background-color']\n",
    "                    align = style['text-align']\n",
    "                    if bgcol == '#ffffc3' and align == 'left':\n",
    "                        child.attrs['class'] = 'type-cell'\n",
    "                    elif bgcol == '#ffffc3' and align == 'right':\n",
    "                        child.attrs['class'] = 'data-cell'\n",
    "                    elif bgcol == '#fff3d9' and align == 'left':\n",
    "                        child.attrs['class'] = 'datalabel-cell'\n",
    "                elif 'colspan' in child.attrs and child['colspan'] == '2':\n",
    "                    child.add_class('description-cell')\n",
    "        elif child.name == 'pre':\n",
    "            #child.string = tidy_str(child.text)\n",
    "            #print('found pre')\n",
    "            # Find if it has a <a> tag with href = \"#*\", if so, replace with <tt>\n",
    "            for a in child.find_all('a', href=re.compile(\"^#\")):\n",
    "                a.name = 'tt'\n",
    "                del a.attrs['href'] \n",
    "            # Go through the text and replace all instances of .TRUE. with <tt>.TRUE.</tt> and similarly with false\n",
    "            child.string = re.sub(r'\\.TRUE\\.', r'<tt>.TRUE.</tt>', child.text)\n",
    "        for attr in to_delete:\n",
    "            if attr in child.attrs:\n",
    "                del child[attr]\n",
    "\n",
    "print(html.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = vars[0]['html']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'border-color:   #b5b500; border-style: solid; border-width: 2; margin-bottom: 10; table-layout: auto; background-color: #FFFFFF;'"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html.attrib['style']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(html_filename, \"r\") as f:\n",
    "    soup = soupparser.fromstring(f)\n",
    "    links = soup.xpath('//a[starts-with(@href, \"#idm\")]')\n",
    "    for a in links:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'v_val(I,J)'"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#idm166337907184'"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link.attrib['href']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Element i at 0x115c02530>"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find parent of link\n",
    "link.getparent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'table'"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html.tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dft-tutor-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
