{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import wikitextparser as wtp\n",
    "import requests\n",
    "\n",
    "from codex.vasp_database import pull_incar_tags, parse\n",
    "USER_AGENT = \"dft-codex/0.0.0 (Omar A. Ashour, ashour@berkeley.edu)\"\n",
    "API_URL = \"https://www.vasp.at/wiki/api.php\"\n",
    "WIKI_URL = \"https://www.vasp.at/wiki/index.php\"\n",
    "REST_API_URL = \"https://www.vasp.at/wiki/rest.php/v1/\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workflow\n",
    "We want to parse 5 specific pages + every INCAR tag.\n",
    "\n",
    "#### Option 1: Database exists\n",
    "1. pull *only* the time stamp of the 5 pages + every INCAR tag.\n",
    "2. compare time stamps to those in the database\n",
    "3. update list of pages to parse, only need those that have been updated\n",
    "4. parse the list of pages\n",
    "\n",
    "#### Option 2: Database doesn't exist\n",
    "1. pull the default list of pages \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "database = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "fudge_dates = True\n",
    "# Change the date on 20 random entries in the database to 1980\n",
    "import random\n",
    "if fudge_dates and database:\n",
    "    for i in range(20):\n",
    "        title = random.choice(list(database.keys()))\n",
    "        database[title][\"last_revised\"] = \"1980-01-01T00:00:00Z\"\n",
    "        print(f\"Changed {title} to 1980-01-01T00:00:00Z\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database doesn't exist. Creating it now.\n",
      "Database created.\n"
     ]
    }
   ],
   "source": [
    "# These are the pages we always want to parse\n",
    "page_titles = [\n",
    "    \"available PAW potentials\",\n",
    "    \"POTCAR\",\n",
    "    \"KPOINTS\",\n",
    "    \"INCAR\",\n",
    "    \"POSCAR\",\n",
    "]\n",
    "\n",
    "if not database:\n",
    "    print(\"Database doesn't exist. Creating it now.\")\n",
    "    pages = parse(page_titles, get_text=True)\n",
    "    pages.extend(pull_incar_tags(parse_text=True))\n",
    "    database = {page[\"title\"]: page for page in pages}\n",
    "    print(\"Database created.\")\n",
    "else:\n",
    "    print(\"Database exists. Checking for updates.\")\n",
    "    pages = parse(page_titles, get_text=False)\n",
    "    pages.extend(pull_incar_tags(parse_text=False))\n",
    "    date_only_database = {page[\"title\"]: page for page in pages}\n",
    "    pages_to_update = []\n",
    "    for title, page in date_only_database.items():\n",
    "        if title not in database or page[\"last_revised\"] != database[title][\"last_revised\"]:\n",
    "            pages_to_update.append(title)\n",
    "    if pages_to_update:\n",
    "        print(\"Updating the following pages:\" + \", \".join(pages_to_update))\n",
    "        updated_pages = parse(pages_to_update, get_text=True)\n",
    "        for page in updated_pages:\n",
    "            title = page[\"title\"]\n",
    "            database[title] = page\n",
    "    else:\n",
    "        print(\"Database is up to date.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_html(title):\n",
    "    pages = []\n",
    "\n",
    "    if not isinstance(title, list):\n",
    "        title = [title]\n",
    "    for t in title:\n",
    "        params = {\n",
    "            \"page\": t,\n",
    "            \"action\": \"parse\",\n",
    "            \"format\": \"json\",\n",
    "            \"formatversion\": \"2\",\n",
    "        }\n",
    "        headers = {\"User-Agent\": USER_AGENT}\n",
    "        req = requests.get(API_URL, headers=headers, params=params)#.json()\n",
    "        pages.append(req.json()['parse']['text'])\n",
    "\n",
    "    return pages\n",
    "\n",
    "# Not available on VASP wiki :(\n",
    "def get_html_rest(title):\n",
    "    pages = []\n",
    "\n",
    "    headers = {\"User-Agent\": USER_AGENT}\n",
    "    if not isinstance(title, list):\n",
    "        title = [title]\n",
    "    for t in title:\n",
    "        url = REST_API_URL + \"page/\" + t + \"/html\"\n",
    "        req = requests.get(url, headers=headers)\n",
    "\n",
    "    return req\n",
    "\n",
    "def get_html_render(title):\n",
    "    pages = []\n",
    "\n",
    "    if not isinstance(title, list):\n",
    "        title = [title]\n",
    "    for t in title:\n",
    "        params = {\n",
    "            \"title\": t,\n",
    "            \"action\": \"render\",\n",
    "        }\n",
    "        headers = {\"User-Agent\": USER_AGENT}\n",
    "        pages.append(requests.get(WIKI_URL, headers=headers, params=params).text)\n",
    "\n",
    "    return pages\n",
    "\n",
    "def get_html_parasoid(text):\n",
    "    pages = []\n",
    "\n",
    "    if not isinstance(text, list):\n",
    "        text = [text]\n",
    "    for t in text:\n",
    "        data = {\n",
    "            \"wikitext\": t,\n",
    "        }\n",
    "        PARSOID_URL = \"https://en.wikipedia.org/api/rest_v1/transform/wikitext/to/html/\"\n",
    "        headers = {\"User-Agent\": USER_AGENT}\n",
    "        req = requests.post(PARSOID_URL, headers=headers, data=data)#, timeout=(None, 3))\n",
    "        pages.append(req.text)\n",
    "\n",
    "    return pages\n",
    "\n",
    "def get_html_rvparse(title):\n",
    "    pages = []\n",
    "\n",
    "    if isinstance(title, list):\n",
    "        if len(title) > 50:\n",
    "            chunks = [title[x : x + 50] for x in range(0, len(title), 50)]\n",
    "            for chunk in chunks:\n",
    "                pages.extend(parse(chunk))\n",
    "            return pages\n",
    "        else:\n",
    "            title = \"|\".join(title)\n",
    "    params = {\n",
    "        \"action\": \"query\",\n",
    "        \"prop\": \"revisions\",\n",
    "        \"rvprop\": \"content\",\n",
    "        \"titles\": title,\n",
    "        \"format\": \"json\",\n",
    "        \"formatversion\": \"2\",\n",
    "        \"rvparse\": \"max\",\n",
    "    }\n",
    "    #if get_text:\n",
    "    #    params[\"rvslots\"] = \"main\"\n",
    "    headers = {\"User-Agent\": USER_AGENT}\n",
    "\n",
    "    req = requests.get(API_URL, headers=headers, params=params).json()\n",
    "    try:\n",
    "        req_pages = req[\"query\"][\"pages\"]\n",
    "    except:\n",
    "        raise ValueError(f\"Something went wrong..., this is the response I got.\\n. {req}\")\n",
    "    return req\n",
    "\n",
    "    for page in req_pages:\n",
    "        title = page[\"title\"]\n",
    "        if len(page[\"revisions\"]) > 1:\n",
    "            print(f\"WARNING: More than one revision found for {title}. Using the first one.\")\n",
    "        rev = page[\"revisions\"][0]\n",
    "        text = rev[\"content\"]\n",
    "        pages.append(text)\n",
    "\n",
    "    return pages\n",
    "\n",
    "#pages = get_html_render([\"ICHARG\", \"SIGMA\"])\n",
    "#print(pages[1])\n",
    "#with open(\"test.html\", \"w\") as f:\n",
    "#    f.write(pages[1])\n",
    "#text = [database['ICHARG']['text'].string, database['SIGMA']['text'].string]\n",
    "#pages = get_html_parsoid(text)\n",
    "#with open(\"test.html\", \"w\") as f:\n",
    "#    f.write(pages[0])\n",
    "\n",
    "files = list(database.keys())\n",
    "#n_pages = len(files) # 50\n",
    "#files = files[:n_pages]\n",
    "#text = [database[files[i]]['text'].string for i in range(n_pages)]\n",
    "##pages = get_html(files)\n",
    "#pages = get_html_parasoid(files)\n",
    "#with open(\"test.html\", \"w\") as f:\n",
    "#    f.write(pages[0])\n",
    "req = get_html_rvparse([\"ICHARG\", \"SIGMA\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pages': [{'pageid': 10,\n",
       "   'ns': 0,\n",
       "   'title': 'ICHARG',\n",
       "   'revisions': [{'content': '<div class=\"mw-parser-output\"><p><a class=\"mw-selflink selflink\">ICHARG</a>&#160;= 0 | 1 | 2 | 4&#160;\\n</p>\\n<table>\\n<tbody><tr>\\n<td>Default: <b>ICHARG</b>\\n</td>\\n<td>= 2\\n</td>\\n<td>if <a href=\"/wiki/index.php/ISTART\" title=\"ISTART\">ISTART</a>=0\\n</td></tr>\\n<tr>\\n<td>\\n</td>\\n<td>= 0\\n</td>\\n<td>else\\n</td></tr>\\n\\n\\n\\n\\n</tbody></table>\\n<p>Description: <a class=\"mw-selflink selflink\">ICHARG</a> determines how VASP constructs the <i>initial</i> charge density.\\n</p>\\n<hr />\\n<ul><li><a class=\"mw-selflink selflink\">ICHARG</a>=0</li></ul>\\n<dl><dd>Calculate the charge density from initial wave functions.</dd>\\n<dd>If <a href=\"/wiki/index.php/ISTART\" title=\"ISTART\">ISTART</a> is <i>internally reset</i> due to an invalid <a href=\"/wiki/index.php/WAVECAR\" title=\"WAVECAR\">WAVECAR</a> file, <a class=\"mw-selflink selflink\">ICHARG</a> will be set to <a class=\"mw-selflink selflink\">ICHARG</a>=2.</dd></dl>\\n<ul><li><a class=\"mw-selflink selflink\">ICHARG</a>=1</li></ul>\\n<dl><dd>Read the charge density from <a href=\"/wiki/index.php/CHGCAR\" title=\"CHGCAR\">CHGCAR</a> file, and extrapolate from the old positions (on <a href=\"/wiki/index.php/CHGCAR\" title=\"CHGCAR\">CHGCAR</a>) to the new positions using a linear combination of atomic charge densities.</dd>\\n<dd>In the <a href=\"/wiki/index.php/Projector-augmented-wave_formalism\" title=\"Projector-augmented-wave formalism\">PAW method</a>, there is however one important point to keep in mind: For the on-site densities (that is the densities within the PAW sphere) only l-decomposed charge densities up to <a href=\"/wiki/index.php/LMAXMIX\" title=\"LMAXMIX\">LMAXMIX</a> are written. Upon restart, the energies might therefore differ slightly from the fully converged energies. The discrepancies can be large for the DFT+U method. In this case, one might need to increase <a href=\"/wiki/index.php/LMAXMIX\" title=\"LMAXMIX\">LMAXMIX</a> to 4 (d-elements) or even 6 (f-elements).</dd></dl>\\n<table style=\"border: 0px solid #2C68FC; padding: 5px; background: #F0F4FF\">\\n<tbody><tr>\\n<td><b><span style=\"color: #2C68FC;\">Tip:</span></b> To improve convergence and reduce the number of electronic steps, it is recommended to set ICHARG = 1 when starting calculations repeatedly with small changes in the input parameters.\\n</td></tr></tbody></table>\\n<ul><li><a class=\"mw-selflink selflink\">ICHARG</a>=2</li></ul>\\n<dl><dd>Take superposition of atomic charge densities.</dd></dl>\\n<ul><li><a class=\"mw-selflink selflink\">ICHARG</a>=4</li></ul>\\n<dl><dd>Read potential from file <a href=\"/wiki/index.php?title=POT&amp;action=edit&amp;redlink=1\" class=\"new\" title=\"POT (page does not exist)\">POT</a>. The local potential on the file <a href=\"/wiki/index.php?title=POT&amp;action=edit&amp;redlink=1\" class=\"new\" title=\"POT (page does not exist)\">POT</a> is written by the optimized-effective-potential methods (OEP), if the flag <a href=\"/wiki/index.php/LVTOT\" title=\"LVTOT\">LVTOT</a>=.TRUE. is supplied in the <a href=\"/wiki/index.php/INCAR\" title=\"INCAR\">INCAR</a> file. Supported as of VASP.5.1.</dd></dl>\\n<ul><li><a class=\"mw-selflink selflink\">ICHARG</a>+10</li></ul>\\n<dl><dd>non-selfconsistent calculations: Adding 10 to the value of <a class=\"mw-selflink selflink\">ICHARG</a>, e.g., <a class=\"mw-selflink selflink\">ICHARG</a>=11 or 12 (or the less convenient value 10) means that the charge density will be kept constant during the <i>entire electronic minimization</i>.</dd></dl>\\n<dl><dd>There are several reasons why to keep the charge density constant:\\n<ul><li><a class=\"mw-selflink selflink\">ICHARG</a>=11</li></ul>\\n<dl><dd>To obtain the eigenvalues (for band-structure plots) or the density of states (DOS) of a given charge density read from <a href=\"/wiki/index.php/CHGCAR\" title=\"CHGCAR\">CHGCAR</a>. The self-consistent <a href=\"/wiki/index.php/CHGCAR\" title=\"CHGCAR\">CHGCAR</a> file must be determined beforehand by a fully self-consistent calculation with a k-point grid spanning the entire Brillouin zone.</dd></dl></dd></dl>\\n<dl><dd><ul><li><a class=\"mw-selflink selflink\">ICHARG</a>=12</li></ul>\\n<dl><dd>Non-self-consistent calculations for a superposition of atomic charge densities. This is in the spirit of the non-self-consistent <a href=\"/wiki/index.php/Harris-Foulkes_functional\" title=\"Harris-Foulkes functional\">Harris-Foulkes functional</a>. The stress and the forces calculated by VASP are correct, and it is absolutely possible to perform an ab-initio MD for the non-selfconsistent <a href=\"/wiki/index.php/Harris-Foulkes_functional\" title=\"Harris-Foulkes functional\">Harris-Foulkes functional</a>.</dd></dl></dd></dl>\\n<dl><dd><table style=\"border: 0px solid #2C68FC; padding: 5px; background: #F0F4FF\">\\n<tbody><tr>\\n<td><b><span style=\"color: #2C68FC;\">Tip:</span></b> If <a class=\"mw-selflink selflink\">ICHARG</a> is set to 11 or 12, it is strongly recommended to set <a href=\"/wiki/index.php/LMAXMIX\" title=\"LMAXMIX\">LMAXMIX</a> to twice the maximum l-quantum number in the pseudopotentials. Thus, for s and p elements <a href=\"/wiki/index.php/LMAXMIX\" title=\"LMAXMIX\">LMAXMIX</a> should be set to 2, for d elements <a href=\"/wiki/index.php/LMAXMIX\" title=\"LMAXMIX\">LMAXMIX</a> should be set to 4, and for f elements <a href=\"/wiki/index.php/LMAXMIX\" title=\"LMAXMIX\">LMAXMIX</a> should be set to 6.\\n</td></tr></tbody></table></dd></dl>\\n<p>The initial charge density is of importance in the following cases:\\n</p>\\n<ul><li>If <a class=\"mw-selflink selflink\">ICHARG</a>&#8805;10 the charge density remains constant during the run.</li></ul>\\n<ul><li>For all algorithms except <a href=\"/wiki/index.php/IALGO\" title=\"IALGO\">IALGO</a>=5X the initial charge density is used to set up the initial Hamiltonian that is used in the first few non-selfconsistent steps, c.f., <a href=\"/wiki/index.php/NELMDL\" title=\"NELMDL\">NELMDL</a> tag.</li></ul>\\n<h2><span class=\"mw-headline\" id=\"Related_tags_and_articles\">Related tags and articles</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/wiki/index.php?title=ICHARG&amp;veaction=edit&amp;section=1\" class=\"mw-editsection-visualeditor\" title=\"Edit section: Related tags and articles\">edit</a><span class=\"mw-editsection-divider\"> | </span><a href=\"/wiki/index.php?title=ICHARG&amp;action=edit&amp;section=1\" title=\"Edit section: Related tags and articles\">edit source</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\\n<p><a href=\"/wiki/index.php/CHGCAR\" title=\"CHGCAR\">CHGCAR</a>, <a href=\"/wiki/index.php/ISTART\" title=\"ISTART\">ISTART</a>, <a href=\"/wiki/index.php/LCHARG\" title=\"LCHARG\">LCHARG</a>, <a href=\"/wiki/index.php/LMAXMIX\" title=\"LMAXMIX\">LMAXMIX</a>, <a href=\"/wiki/index.php/NELMDL\" title=\"NELMDL\">NELMDL</a>, <a href=\"/wiki/index.php/INIWAV\" title=\"INIWAV\">INIWAV</a>\\n</p><p><a href=\"/wiki/index.php/Special:Search/%22ICHARG%22_incategory:%22Examples%22\" title=\"Special:Search/&quot;ICHARG&quot; incategory:&quot;Examples&quot;\">Examples that use this tag</a>\\n</p>\\n<hr /></div>'}]},\n",
       "  {'pageid': 184, 'ns': 0, 'title': 'SIGMA'}]}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "req['query']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking\n",
    "Action API: 0.6s/page\n",
    "\n",
    "Render: 0.6s/page\n",
    "\n",
    "Rest API: 0.6s/page (can't actually get HTML so...)\n",
    "\n",
    "Wikipedia Paradoid: ~0.3s/page but shitty formatting (sort of)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#req = get_html(\"INCAR\")\n",
    "#myjson = req.json()\n",
    "# html_string = myjson['parse']['text']\n",
    "#with open(\"test.html\", \"w\") as f:\n",
    "#    f.write(html_string)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STRETCH GOAL\n",
    "The formatting of these things is utter shit, it might be really diffcult to do the comment to explain value thing...\n",
    "\n",
    "Look at the difference between ISMEAR and ICHARG. They're in lists, with possible indented list subitems, descriptions on same line or not, typos meaning there's no '=' after the value....\n",
    "\n",
    "Focus on the HTML webpage for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['=0', '=1', '=2', '=4', '+10']\n"
     ]
    }
   ],
   "source": [
    "tag = \"ICHARG\"\n",
    "text = database[tag][\"text\"]\n",
    "sections = text.get_sections()\n",
    "options = []\n",
    "#for section in sections:\n",
    "#    if section.title is not None:\n",
    "#        # Strip title of whitespace (leading and trailing)\n",
    "#        if section.title.strip() == \"Tag options\":\n",
    "#            lists = section.get_lists()\n",
    "wikilink=\"*{{TAG|\"+tag+\"}}\"\n",
    "lists = text.get_lists()\n",
    "for lll in lists:\n",
    "    for item in lll.fullitems:\n",
    "        if item.startswith(wikilink):\n",
    "            options.append(item.split(wikilink)[1].strip())\n",
    "\n",
    "print(options)\n",
    "#options_dict = {}\n",
    "#for option in options:\n",
    "#    setting = wtp.parse(option.split(\":\")[0]).plain_text()\n",
    "#    explanation = wtp.parse(option.split(\":\")[1]).plain_text()\n",
    "#    options_dict.update({setting: explanation})\n",
    "\n",
    "#options_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Recommended potentials for DFT calculations \n",
      "Found recommended pseudo: Sr_sv\n",
      "Found recommended pseudo: Y_sv\n",
      "Found recommended pseudo: Zr_sv\n",
      "Found recommended pseudo: Nb_sv\n",
      "Found recommended pseudo: Mo_sv\n",
      "Found recommended pseudo: Tc_pv\n",
      "Found recommended pseudo: Ru_pv\n",
      "Found recommended pseudo: Rh_pv\n",
      "Found recommended pseudo: Pd\n",
      "Found recommended pseudo: Ag\n",
      "Found recommended pseudo: Cd\n",
      "Found recommended pseudo: In_d\n",
      "Found recommended pseudo: Sn_d\n",
      "Found recommended pseudo: Sb\n",
      "Found recommended pseudo: Te\n",
      "Found recommended pseudo: I\n",
      "Found recommended pseudo: Xe\n",
      "Found recommended pseudo: Cs_sv\n",
      "Found recommended pseudo: Ba_sv\n",
      "Found recommended pseudo: La\n",
      "Found recommended pseudo: Ce\n",
      "Found recommended pseudo: Pr_3\n",
      "Found recommended pseudo: Nd_3\n",
      "Found recommended pseudo: Pm_3\n",
      "Found recommended pseudo: Sm_3\n",
      "Found recommended pseudo: Eu_2\n",
      "Found recommended pseudo: Gd_3\n",
      "Found recommended pseudo: Tb_3\n",
      "Found recommended pseudo: Dy_3\n",
      "Found recommended pseudo: Ho_3\n",
      "Found recommended pseudo: Er_3\n",
      "Found recommended pseudo: Tm_3\n",
      "Found recommended pseudo: Yb_2\n",
      "Found recommended pseudo: Lu_3\n",
      "Found recommended pseudo: Hf_pv\n",
      "Found recommended pseudo: Ta_pv\n",
      "Found recommended pseudo: W_sv\n",
      "Found recommended pseudo: Re\n",
      "Found recommended pseudo: Os\n",
      "Found recommended pseudo: Ir\n",
      "Found recommended pseudo: Pt\n",
      "Found recommended pseudo: Au\n",
      "Found recommended pseudo: Hg\n",
      "Found recommended pseudo: Tl_d\n",
      "Found recommended pseudo: Pb_d\n",
      "Found recommended pseudo: Bi_d\n",
      "Found recommended pseudo: Po_d\n",
      "Found recommended pseudo: At\n",
      "Found recommended pseudo: Rn\n",
      "Found recommended pseudo: Fr_sv\n",
      "Found recommended pseudo: Ra_sv\n",
      "Found recommended pseudo: Ac\n",
      "Found recommended pseudo: Th\n",
      "Found recommended pseudo: Pa\n",
      "Found recommended pseudo: U\n",
      "Found recommended pseudo: Np\n",
      "Found recommended pseudo: Pu\n",
      "Found recommended pseudo: Am\n",
      "Found recommended pseudo: Cm\n",
      " Recommended potentials for GW/RPA calculations \n"
     ]
    }
   ],
   "source": [
    "tag = \"Available PAW potentials\"\n",
    "text = database[tag][\"text\"]\n",
    "sections = text.get_sections()[1:3]\n",
    "bolds = []\n",
    "for section in sections:\n",
    "    print(section.title)\n",
    "    for b in section.get_bolds():\n",
    "        try:\n",
    "            float(b.plain_text())\n",
    "        except:\n",
    "            print(\"Found recommended pseudo: \" + b.plain_text())\n",
    "            # TODO: doesn't work for the GW ones....\n",
    "            bolds.append(b.plain_text())\n",
    "\n",
    "#bolds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dft-tutor-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
