{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikitextparser as wtp\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_URL = \"https://www.vasp.at/wiki/api.php\"\n",
    "# API_URL = \"https://en.wikipedia.org/w/api.php\"\n",
    "\n",
    "\n",
    "# action=query&generator=categorymembers&gcmtitle=Category:Physics&prop=categories&cllimit=max&gcmlimit=max\n",
    "def get_category(category, gcmcontinue=None):\n",
    "    params = {\n",
    "        \"action\": \"query\",\n",
    "        \"generator\": \"categorymembers\",\n",
    "        \"prop\": \"revisions\",\n",
    "        \"gcmlimit\": \"max\",\n",
    "        \"gcmtitle\": category,\n",
    "        \"format\": \"json\",\n",
    "        \"formatversion\": \"2\",\n",
    "    }\n",
    "    if gcmcontinue:\n",
    "        params[\"gcmcontinue\"] = gcmcontinue\n",
    "\n",
    "    # TODO: parse version from setup.py or something?\n",
    "    headers = {\"User-Agent\": \"dft-tutor/0.0.0\"}\n",
    "    req = requests.get(API_URL, headers=headers, params=params).json()\n",
    "\n",
    "    # Figure out if we need to parse more pages\n",
    "    gcmcontinue = None\n",
    "    if \"continue\" in req:\n",
    "        gcmcontinue = req[\"continue\"][\"gcmcontinue\"]\n",
    "\n",
    "    pages = []\n",
    "    for page in req[\"query\"][\"pages\"]:\n",
    "        pages.append(\n",
    "            {\n",
    "                \"pageid\": page[\"pageid\"],\n",
    "                \"title\": page[\"title\"],\n",
    "                \"last_revised\": page[\"revisions\"][0][\"timestamp\"],\n",
    "                \"text\": None,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return pages, gcmcontinue\n",
    "\n",
    "def pull_incar_tags(parse_text=True):\n",
    "    pages, gcmcontinue = get_category(\"Category:INCAR tag\")\n",
    "    while gcmcontinue is not None:\n",
    "        cont_pages, gcmcontinue = get_category(\n",
    "            \"Category:INCAR tag\", gcmcontinue=gmcontinue\n",
    "        )\n",
    "        pages.extend(cont_pages)\n",
    "\n",
    "    # This entry breaks the wiki...\n",
    "    bad_entry = \"Construction:LKPOINTS WAN\"\n",
    "    titles = [page[\"title\"] for page in pages]\n",
    "    if bad_entry in titles:\n",
    "        # Pop from pages\n",
    "        pages.pop(titles.index(bad_entry))\n",
    "\n",
    "    if parse_text:\n",
    "        page_titles = [page[\"title\"] for page in pages]\n",
    "        pages = parse(page_titles)\n",
    "    return pages\n",
    "\n",
    "\n",
    "def parse(title, get_text=True):\n",
    "    pages = []\n",
    "\n",
    "    rvprop = \"timestamp\"\n",
    "    if get_text:\n",
    "        rvprop += \"|content\"\n",
    "    if isinstance(title, list):\n",
    "        if len(title) > 50:\n",
    "            chunks = [title[x : x + 50] for x in range(0, len(title), 50)]\n",
    "            for chunk in chunks:\n",
    "                pages.extend(parse(chunk, get_text=get_text))\n",
    "            return pages\n",
    "        else:\n",
    "            title = \"|\".join(title)\n",
    "    params = {\n",
    "        \"action\": \"query\",\n",
    "        \"prop\": \"revisions\",\n",
    "        \"rvprop\": rvprop,\n",
    "        \"titles\": title,\n",
    "        \"format\": \"json\",\n",
    "        \"formatversion\": \"2\",\n",
    "    }\n",
    "    if get_text:\n",
    "        params[\"rvslots\"] = \"main\"\n",
    "    headers = {\"User-Agent\": \"dft-tutor/0.0.0\"}\n",
    "\n",
    "    req = requests.get(API_URL, headers=headers, params=params).json()\n",
    "    try:\n",
    "        req_pages = req[\"query\"][\"pages\"]\n",
    "    except:\n",
    "        raise ValueError(f\"Something went wrong..., this is the response I got.\\n. {req}\")\n",
    "\n",
    "    for page in req_pages:\n",
    "        pageid = page[\"pageid\"]\n",
    "        title = page[\"title\"]\n",
    "        rev = page[\"revisions\"][0]\n",
    "        timestamp = rev[\"timestamp\"]\n",
    "        text = None\n",
    "        if get_text:\n",
    "            text = wtp.parse(rev[\"slots\"][\"main\"][\"content\"])\n",
    "        pages.append({\"pageid\": pageid, \"title\": title, \"last_revised\": timestamp, \"text\": text})\n",
    "\n",
    "    return pages\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workflow\n",
    "We want to parse 5 specific pages + every INCAR tag.\n",
    "\n",
    "#### Option 1: Database exists\n",
    "1. pull *only* the time stamp of the 5 pages + every INCAR tag.\n",
    "2. compare time stamps to those in the database\n",
    "3. update list of pages to parse, only need those that have been updated\n",
    "4. parse the list of pages\n",
    "\n",
    "#### Option 2: Database doesn't exist\n",
    "1. pull the default list of pages \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "database = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fudge_dates = True\n",
    "# Change the date on 20 random entries in the database to 1980\n",
    "import random\n",
    "if fudge_dates and database:\n",
    "    for i in range(20):\n",
    "        title = random.choice(list(database.keys()))\n",
    "        database[title][\"last_revised\"] = \"1980-01-01T00:00:00Z\"\n",
    "        print(f\"Changed {title} to 1980-01-01T00:00:00Z\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database doesn't exist. Creating it now.\n",
      "Database creared.\n"
     ]
    }
   ],
   "source": [
    "# These are the pages we always want to parse\n",
    "page_titles = [\n",
    "    \"available PAW potentials\",\n",
    "    \"POTCAR\",\n",
    "    \"KPOINTS\",\n",
    "    \"INCAR\",\n",
    "    \"POSCAR\",\n",
    "]\n",
    "if not database:\n",
    "    print(\"Database doesn't exist. Creating it now.\")\n",
    "    pages = parse(page_titles, get_text=True)\n",
    "    pages.extend(pull_incar_tags(parse_text=True))\n",
    "    database = {page[\"title\"]: page for page in pages}\n",
    "    print(\"Database creared.\")\n",
    "else:\n",
    "    print(\"Database exists. Checking for updates.\")\n",
    "    pages = parse(page_titles, get_text=False)\n",
    "    pages.extend(pull_incar_tags(parse_text=False))\n",
    "    date_only_database = {page[\"title\"]: page for page in pages}\n",
    "    pages_to_update = []\n",
    "    for title, page in date_only_database.items():\n",
    "        if title not in database or page[\"last_revised\"] != database[title][\"last_revised\"]:\n",
    "            pages_to_update.append(title)\n",
    "    if pages_to_update:\n",
    "        print(\"Updating the following pages:\" + \", \".join(pages_to_update))\n",
    "        updated_pages = parse(pages_to_update, get_text=True)\n",
    "        for page in updated_pages:\n",
    "            title = page[\"title\"]\n",
    "            database[title] = page\n",
    "    else:\n",
    "        print(\"Database is up to date.\")\n",
    "\n",
    "# TODO: put underscores back in keys"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STRETCH GOAL\n",
    "The formatting of these things is utter shit, it might be really diffcult to do the comment to explain value thing...\n",
    "\n",
    "Look at the difference between ISMEAR and ICHARG. They're in lists, with possible indented list subitems, descriptions on same line or not, typos meaning there's no '=' after the value....\n",
    "\n",
    "Focus on the HTML webpage for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['=0', '=1', '=2', '=4', '+10']\n"
     ]
    }
   ],
   "source": [
    "tag = \"ICHARG\"\n",
    "text = database[tag][\"text\"]\n",
    "sections = text.get_sections()\n",
    "options = []\n",
    "#for section in sections:\n",
    "#    if section.title is not None:\n",
    "#        # Strip title of whitespace (leading and trailing)\n",
    "#        if section.title.strip() == \"Tag options\":\n",
    "#            lists = section.get_lists()\n",
    "wikilink=\"*{{TAG|\"+tag+\"}}\"\n",
    "lists = text.get_lists()\n",
    "for list in lists:\n",
    "    for item in list.fullitems:\n",
    "        if item.startswith(wikilink):\n",
    "            options.append(item.split(wikilink)[1].strip())\n",
    "\n",
    "print(options)\n",
    "#options_dict = {}\n",
    "#for option in options:\n",
    "#    setting = wtp.parse(option.split(\":\")[0]).plain_text()\n",
    "#    explanation = wtp.parse(option.split(\":\")[1]).plain_text()\n",
    "#    options_dict.update({setting: explanation})\n",
    "\n",
    "#options_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Recommended potentials for DFT calculations \n",
      "Found recommended pseudo: Sr_sv\n",
      "Found recommended pseudo: Y_sv\n",
      "Found recommended pseudo: Zr_sv\n",
      "Found recommended pseudo: Nb_sv\n",
      "Found recommended pseudo: Mo_sv\n",
      "Found recommended pseudo: Tc_pv\n",
      "Found recommended pseudo: Ru_pv\n",
      "Found recommended pseudo: Rh_pv\n",
      "Found recommended pseudo: Pd\n",
      "Found recommended pseudo: Ag\n",
      "Found recommended pseudo: Cd\n",
      "Found recommended pseudo: In_d\n",
      "Found recommended pseudo: Sn_d\n",
      "Found recommended pseudo: Sb\n",
      "Found recommended pseudo: Te\n",
      "Found recommended pseudo: I\n",
      "Found recommended pseudo: Xe\n",
      "Found recommended pseudo: Cs_sv\n",
      "Found recommended pseudo: Ba_sv\n",
      "Found recommended pseudo: La\n",
      "Found recommended pseudo: Ce\n",
      "Found recommended pseudo: Pr_3\n",
      "Found recommended pseudo: Nd_3\n",
      "Found recommended pseudo: Pm_3\n",
      "Found recommended pseudo: Sm_3\n",
      "Found recommended pseudo: Eu_2\n",
      "Found recommended pseudo: Gd_3\n",
      "Found recommended pseudo: Tb_3\n",
      "Found recommended pseudo: Dy_3\n",
      "Found recommended pseudo: Ho_3\n",
      "Found recommended pseudo: Er_3\n",
      "Found recommended pseudo: Tm_3\n",
      "Found recommended pseudo: Yb_2\n",
      "Found recommended pseudo: Lu_3\n",
      "Found recommended pseudo: Hf_pv\n",
      "Found recommended pseudo: Ta_pv\n",
      "Found recommended pseudo: W_sv\n",
      "Found recommended pseudo: Re\n",
      "Found recommended pseudo: Os\n",
      "Found recommended pseudo: Ir\n",
      "Found recommended pseudo: Pt\n",
      "Found recommended pseudo: Au\n",
      "Found recommended pseudo: Hg\n",
      "Found recommended pseudo: Tl_d\n",
      "Found recommended pseudo: Pb_d\n",
      "Found recommended pseudo: Bi_d\n",
      "Found recommended pseudo: Po_d\n",
      "Found recommended pseudo: At\n",
      "Found recommended pseudo: Rn\n",
      "Found recommended pseudo: Fr_sv\n",
      "Found recommended pseudo: Ra_sv\n",
      "Found recommended pseudo: Ac\n",
      "Found recommended pseudo: Th\n",
      "Found recommended pseudo: Pa\n",
      "Found recommended pseudo: U\n",
      "Found recommended pseudo: Np\n",
      "Found recommended pseudo: Pu\n",
      "Found recommended pseudo: Am\n",
      "Found recommended pseudo: Cm\n",
      " Recommended potentials for GW/RPA calculations \n"
     ]
    }
   ],
   "source": [
    "tag = \"Available PAW potentials\"\n",
    "text = database[tag][\"text\"]\n",
    "sections = text.get_sections()[1:3]\n",
    "bolds = []\n",
    "for section in sections:\n",
    "    print(section.title)\n",
    "    for b in section.get_bolds():\n",
    "        try:\n",
    "            float(b.plain_text())\n",
    "        except:\n",
    "            print(\"Found recommended pseudo: \" + b.plain_text())\n",
    "            # TODO: doesn't work for the GW ones....\n",
    "            bolds.append(b.plain_text())\n",
    "\n",
    "#bolds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dft-tutor-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
